---
sidebar_position: 2
title: 模型
---

**LLMOS** 平台提供全面的模型管理功能，允许您在仓库中存储、组织和管理机器学习模型。模型可以存储在私有仓库中，并在本地缓存以实现更快的部署和改进的性能。

![models-list](/img/docs/model-list.png)

## 概述

LLMOS 中的模型作为管理机器学习资产的集中方式。您可以：

- **在仓库中存储模型**：在私有仓库中上传和组织模型文件
- **文件管理**：通过直观的界面查看、上传和下载模型文件
- **上传命令**：生成用于从应用程序（如 [Notebooks](../notebooks.md)）上传模型的脚本
- **本地模型缓存**：创建本地模型副本以实现更快的模型服务部署
- **版本控制**：本地模型支持版本控制

## 创建模型

您可以从 **AI 基础设施管理 > 模型管理 > 模型** 页面创建模型。

### 通用配置

1. **命名空间**：选择模型的命名空间。
2. **名称**：为您的模型输入唯一名称。
3. **描述**：提供更好地描述此模型的描述。
4. **仓库**：选择将存储模型的仓库。

![model-create-general](/img/docs/model-create.png)

## 管理模型文件

创建模型后，您可以通过模型详情页面管理其文件。

### 文件操作

模型文件管理界面提供多种操作：

- **查看文件**：浏览模型的文件结构和内容
- **上传文件**：向模型添加新文件
- **下载文件**：下载单个文件或整个文件夹
- **创建文件夹**：以分层结构组织文件
- **删除文件**：删除不必要的文件

![model-files](/img/docs/model-files.png)

### 文件上传方法

#### 直接上传

您可以通过 Web 界面直接上传文件：

1. 在模型文件视图中点击 **上传文件**
2. 从本地系统选择文件
3. 在模型内选择目标文件夹
4. 点击 **上传** 传输文件

#### 命令行上传

对于程序化上传或与开发工作流程的集成，LLMOS 提供上传命令：

1. 在模型文件视图中点击 **生成上传命令**
2. 在 **文件** 或 **文件夹** 上传模式之间选择
3. 复制生成的 Python 脚本
4. 在您的开发环境中运行脚本（例如，[Notebooks](../notebooks.md)）

![model-upload-command](/img/docs/model-upload-command.png)

:::note
**API 令牌安全**

API 密钥将在 30 分钟后过期。您可以访问 [API 密钥](../user_and_auth/api-keys) 页面来管理您自己的 API 密钥以获得更好的安全性。
:::

## 本地模型

本地模型是仓库存储模型的缓存副本，预下载到本地存储。此功能通过消除在部署期间下载模型文件的需要，显著改善了模型服务启动时间。

![local-models](/img/docs/local-model-list.png)

### 先决条件

:::warning
**Ceph 存储要求**

本地模型功能依赖于 Ceph 存储。在使用本地模型之前，您必须启用和配置 Ceph 存储。
:::

### 创建本地模型

从现有仓库模型创建本地模型：

1. 导航到模型详情页面
2. 点击 **创建本地模型**
3. 配置本地模型设置：
   - **新版本**：指定本地模型的版本
   - **仓库**：源仓库（自动填充）
   - **命名空间**：选择目标命名空间
4. 点击 **创建** 开始本地缓存过程

![local-models](/img/docs/local-model-create.png)

### 本地模型版本控制

本地模型支持版本控制，允许您维护同一模型的多个版本。当您需要回滚到以前的版本或比较不同的模型迭代时，这特别有用。

![local-models](/img/docs/local-model-version.png)

### 本地模型优势

- **更快的部署**：模型文件已在本地可用
- **减少网络流量**：部署期间无需从仓库下载
- **改进的可靠性**：减少对外部仓库可用性的依赖
- **更好的性能**：消除模型服务启动时的下载时间

### 在模型服务中使用本地模型

创建 [模型服务](../modelservice.md) 时，您可以选择本地模型作为模型源。
